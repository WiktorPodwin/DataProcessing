{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/jovyan/work/model/src/preprocess_data.ipynb import PreProcess\n",
    "%run /home/jovyan/work/operations/db_operations.ipynb import DataOperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from typing import List, Annotated, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(spark: SparkSession,\n",
    "               categorical_features: List[str],\n",
    "               numeric_features: List[str],\n",
    "               targets: List[str]\n",
    "               ) -> Tuple[\n",
    "                   Annotated[dict, \"training_dataset\"], \n",
    "                   Annotated[dict, \"validation_dataset\"],\n",
    "                   Annotated[dict, \"test_dataset\"],\n",
    "                   Annotated[list, \"merge_models\"],\n",
    "                   Annotated[list, \"inputs\"]\n",
    "                   ]:\n",
    "    \"\"\"\n",
    "    Handles preprocessing operations and saves processed datasets into database\n",
    "    \n",
    "    Args:\n",
    "        spark: Active SparkSession\n",
    "        categorical_features: List of categorical columns\n",
    "        numeric_features: List of numeric columns\n",
    "        targets: List of targets\n",
    "    Returns:\n",
    "        Tuple[\n",
    "        Annotated[dict, \"training_dataset\"], \n",
    "        Annotated[dict, \"validation_dataset\"],\n",
    "        Annotated[dict, \"test_dataset\"],\n",
    "        Annotated[list, \"merge_models\"],\n",
    "        Annotated[list, \"inputs\"]\n",
    "        ]:\n",
    "            - training_dataset: Dictionary with training dataset\n",
    "            - test_dataset: Dictionary with test dataset\n",
    "            - validation_dataset: Dictionary with validation dataset\n",
    "            - merge_models: A tensor representing concatenated continuous features Inputs \n",
    "                            and embeddings for the categoircal features \n",
    "            - inputs: A List containing inputs layers for each feature\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"Started preprocessing\")\n",
    "        data_oper = DataOperations(spark=spark)\n",
    "        df = data_oper.load_data(\"cleaned_data\")\n",
    "        train = data_oper.load_data(\"train\")\n",
    "        val = data_oper.load_data(\"val\")\n",
    "        test = data_oper.load_data(\"test\")\n",
    "        \n",
    "        preprocess = PreProcess()\n",
    "        \n",
    "        merge_models, inputs = preprocess.embedding_categorical_data(df=df, \n",
    "                                                                     categorical_features=categorical_features, \n",
    "                                                                     numeric_features=numeric_features)\n",
    "\n",
    "        training_dataset = preprocess.prepare_for_model(df=train,\n",
    "                                                        df_name=\"training\", \n",
    "                                                        categorical_features=categorical_features, \n",
    "                                                        number_features=numeric_features, \n",
    "                                                        targets=targets)\n",
    "        \n",
    "        test_dataset = preprocess.prepare_for_model(df=val, \n",
    "                                                    df_name=\"validation\",                                                 \n",
    "                                                    categorical_features=categorical_features, \n",
    "                                                    number_features=numeric_features, \n",
    "                                                    targets=targets)\n",
    "        \n",
    "        validation_dataset = preprocess.prepare_for_model(df=test, \n",
    "                                                          df_name=\"test\", \n",
    "                                                          categorical_features=categorical_features, \n",
    "                                                          number_features=numeric_features, \n",
    "                                                          targets=targets)\n",
    "        logging.info(\"Successfully finished preprocessing \\n\")\n",
    "        return training_dataset, validation_dataset, test_dataset, merge_models, inputs\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data preprocessing: {e}\")\n",
    "        raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

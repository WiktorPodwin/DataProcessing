{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pydot -y\n",
    "# !conda install pydotplus -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatePlot:\n",
    "    \"\"\"\n",
    "    Class for creating model plots\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 directory: str = \"/home/jovyan/work/model/plots\"\n",
    "                 ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            directory: A path to the directory to save an image\n",
    "        \"\"\"\n",
    "        self.directory = directory\n",
    "\n",
    "    def visualize_model(self, model: Model) -> None:\n",
    "        \"\"\"\n",
    "        Creates a TensorFlow neural network visualization\n",
    "        \n",
    "        Args:\n",
    "            model: Allready existing neural network\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file_name = \"model_schema.png\"\n",
    "            file_path = self.directory + \"/\" + file_name\n",
    "            os.makedirs(self.directory, exist_ok=True)\n",
    "\n",
    "            plot_model(model, \n",
    "                       show_dtype=True,\n",
    "                       show_layer_names=True,\n",
    "                       show_shapes=True,\n",
    "                       to_file=file_path)\n",
    "            logging.info(\"Successfully created model visualization\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while creating model visualization: {e}\")\n",
    "            raise e\n",
    "    \n",
    "\n",
    "    def differences(self, \n",
    "                    true_value: np.ndarray, \n",
    "                    predicted_value: np.ndarray, \n",
    "                    title: str = \"\"\n",
    "                    ) -> None:\n",
    "        \"\"\"\n",
    "        Visualizes differences between true and predicted labels\n",
    "        \n",
    "        Args:\n",
    "            true_value: An array containing true values \n",
    "            predicted_value: An array containing predicted values\n",
    "            title: A name of label as a title for a plot\n",
    "        \"\"\"\n",
    "        try:\n",
    "            predicted_value = predicted_value.reshape((len(true_value, )))\n",
    "            residuals = np.abs(true_value - predicted_value)\n",
    "            plt.scatter(true_value, residuals)\n",
    "            plt.xlabel('True Values')\n",
    "            plt.ylabel('Predicted Values')\n",
    "            plt.title(f\"Differences between true and predicted labels in {title}_score\")\n",
    "            plt.grid(True)\n",
    "\n",
    "            os.makedirs(self.directory, exist_ok=True)\n",
    "            file_path = self.directory + \"/\" + title + \"_difference\"\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "            logging.info(f\"Successfully saved an image to the file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erorr in visualizaion differences between true and prediction labels: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def conf_matrix(self,\n",
    "                    conf_mat: np.ndarray,\n",
    "                    title: str = \"\"\n",
    "                    ) -> None:\n",
    "        \"\"\"\n",
    "        Creates a confusion matrix plot\n",
    "        \n",
    "        Args:\n",
    "            conf_mat: Confusion matrix to display\n",
    "            title: A name of label as a title for a plot\n",
    "        \"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            sns.heatmap(conf_mat, cmap=\"Blues\", annot=True, fmt='d')\n",
    "            plt.xlabel(\"Predicted Scores\")\n",
    "            plt.ylabel(\"True Scores\")\n",
    "            plt.title(f\"Confusion matrix for {title}_score\")\n",
    "\n",
    "            file_path = self.directory + \"/\" + title + \"_confusion_matrix\"\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "            logging.info(f\"Successfully saved an image to the file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while creating confusion matrix visualization: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def metrics_history(self, history: History, metrics: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Plot history of improvement metrics during training on epochs\n",
    "        \n",
    "        Args:\n",
    "            history: A dictionary storing metrics values from training\n",
    "            metrics: A list of keys from history dictionary to plot\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                plt.plot(history.history[metric], label=metric)\n",
    "\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Metrics\")\n",
    "            plt.title(\"Metrics history\")\n",
    "            plt.legend()\n",
    "            plt.grid(visible=True)\n",
    "\n",
    "            file_path = self.directory + \"/metrics\"\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "            logging.info(f\"Successfully saved an image to the file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while creating metrics visualization: {e}\")\n",
    "            raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

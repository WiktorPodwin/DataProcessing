{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/jovyan/work/database_operations/db_operations.ipynb import DataOperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Tuple, Annotated, List\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, when, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformData:\n",
    "    \"\"\"\n",
    "    Class for preparing dataset into model predictions\n",
    "    \"\"\"\n",
    "\n",
    "    def check_empty_fields(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Deletes rows with empty fields\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame befor transformation\n",
    "        Returns:\n",
    "            DataFrame: DataFrame after transformation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = df.dropna()\n",
    "            logging.info(\"\\nSuccessfully deleted emty fields\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while cleaning 'results' dataset: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def filter_data(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Picks only nedded data from DataFrame\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame before transformation\n",
    "        Return:\n",
    "            DataFrame: A DataFrame after transformation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = df.filter(df.year >= 1980)\n",
    "            logging.info(\"Successfully filtered data\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in data filtering: {e}\")\n",
    "            raise e\n",
    "        \n",
    "    def convert_date_into_years(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Converts date into years\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame befor trainsformation\n",
    "        Returns:\n",
    "            DataFrame: DataFrame after \"date\" feature transformation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = df.withColumn(\"year\", year(\"date\"))\n",
    "            df = df.drop(\"date\")\n",
    "            logging.info(\"Successfully changed date into years\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in converting date into years: {e}\")\n",
    "            raise e\n",
    "    \n",
    "        \n",
    "    def string_into_numeric(self, df: DataFrame) -> Tuple[\n",
    "        Annotated[DataFrame, \"df\"],\n",
    "        Annotated[list, \"categorical_features\"],\n",
    "        Annotated[list, \"numeric_features\"],\n",
    "        Annotated[list, \"targets\"]\n",
    "        ]:\n",
    "        \"\"\"\n",
    "        Changes features with string data type into numeric\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame befor transformation\n",
    "        Returns:\n",
    "                Tuple[\n",
    "            Annotated[DataFrame, \"df\"],\n",
    "            Annotated[list, \"categorical_features\"],\n",
    "            Annotated[list, \"numeric_features\"],\n",
    "            Annotated[list, \"targets\"]\n",
    "            ]: \n",
    "            - df: DataFrame befor transformation\n",
    "            - categorical_features: List of categorical features\n",
    "            - numeric_features: List of numeric features\n",
    "            - targets: List of targets\n",
    "        \"\"\"\n",
    "        try:\n",
    "            categorical_features = [\"away_team\", \"city\", \"country\", \"home_team\", \"year\", \"tournament\"]\n",
    "            numeric_features = [\"neutral\"]\n",
    "            targets = [\"home_score\", \"away_score\"]\n",
    "            original_columns = df.columns\n",
    "            columns_to_transformation = [org_col for org_col in original_columns if org_col not in targets and org_col != \"year\"]\n",
    "\n",
    "            combined_home_away_team = df.select(col(\"home_team\") \\\n",
    "                                      .alias(\"team\")) \\\n",
    "                                      .union(df.select(col(\"away_team\") \\\n",
    "                                      .alias(\"team\"))) \\\n",
    "                                      .distinct()\n",
    "            \n",
    "            team_indexer = StringIndexer(inputCol=\"team\", outputCol=\"team_index\")\n",
    "            indexed_team = team_indexer.fit(combined_home_away_team).transform(combined_home_away_team)\n",
    "\n",
    "            df_with_home_index = df \\\n",
    "                .join(indexed_team.withColumnRenamed(\"team_index\", \"home_team_index\"), \n",
    "                      df.home_team == indexed_team.team, \"left\") \\\n",
    "                .drop(\"team\")\n",
    "            \n",
    "            df = df_with_home_index \\\n",
    "                .join(indexed_team.withColumnRenamed(\"team_index\", \"away_team_index\"), \n",
    "                      df_with_home_index.away_team == indexed_team.team, \"left\") \\\n",
    "                .drop(\"team\")\n",
    "                    \n",
    "            string_categorcial = [\"city\", \"country\", \"tournament\"]\n",
    "            for cat in string_categorcial:\n",
    "                string_indexer = StringIndexer(inputCol=cat, outputCol=cat + \"_index\")\n",
    "                df = string_indexer.fit(df).transform(df)\n",
    "\n",
    "            df = df.withColumn(\"neutral_index\", when(col(\"neutral\") == True, 1).otherwise(0))\n",
    "\n",
    "            for tr_col in columns_to_transformation:\n",
    "                df = df.drop(tr_col)\n",
    "            \n",
    "            for new_col in df.columns:\n",
    "                for col_to_trans in columns_to_transformation:\n",
    "                    if new_col == col_to_trans + \"_index\":\n",
    "                        df = df.withColumnRenamed(new_col, col_to_trans)\n",
    "            \n",
    "            df = df.select(*original_columns)\n",
    "            logging.info(\"Successfully converted string features into numeric\")\n",
    "            return df, categorical_features, numeric_features, targets\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while changing string features into numeric: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform_strategy(spark: SparkSession, df: DataFrame) -> Tuple[\n",
    "        Annotated[List[str], \"categorical_features\"], \n",
    "        Annotated[List[str], \"numeric_features\"],\n",
    "        Annotated[List[str], \"targets\"]\n",
    "        ]:\n",
    "    \"\"\"\n",
    "    Handles TransformData operations \n",
    "    \n",
    "    Args:\n",
    "        spark: Active SparkSession\n",
    "        df: Dataset for transforming\n",
    "    Returns:\n",
    "        Tuple[\n",
    "        Annotated[List[str], \"categorical_features\"], \n",
    "        Annotated[List[str], \"numeric_features\"],\n",
    "        Annotated[List[str], \"targets\"]\n",
    "        ]:\n",
    "            - categorical_features: List of categorical columns\n",
    "            - numeric_features: List of numeric columns\n",
    "            - targets: List of targets\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        transform_data = TransformData()\n",
    "        deleted_empty_fields = transform_data.check_empty_fields(df)\n",
    "        date_into_years = transform_data.convert_date_into_years(deleted_empty_fields)\n",
    "        filtered_data = transform_data.filter_data(date_into_years)\n",
    "        string_into_numeric, categorical_features, numeric_features, targets = transform_data.string_into_numeric(df=filtered_data)\n",
    "        \n",
    "        db_operations = DataOperations(spark)\n",
    "        db_operations.save_data(df=string_into_numeric, table_name=\"cleaned_data\")\n",
    "\n",
    "        return categorical_features, numeric_features, targets\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data transformation: {e}\")\n",
    "        raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install tensorflow\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, when, year\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from typing import Tuple, Annotated, List, Dict, Union\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformData:\n",
    "    \"\"\"\n",
    "    Class for preparing dataset into model predictions\n",
    "    \"\"\"\n",
    "\n",
    "    def check_empty_fields(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Deletes rows with empty fields\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame befor transformation\n",
    "        Returns:\n",
    "            DataFrame: DataFrame after transformation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = df.dropna()\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while cleaning 'results' dataset: {e}\")\n",
    "            raise e\n",
    "        \n",
    "    def convert_date_into_years(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Converts date into years\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame befor trainsformation\n",
    "        Returns:\n",
    "            DataFrame: DataFrame after \"date\" feature transformation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = df.withColumn(\"year\", year(\"date\"))\n",
    "            df = df.drop(\"date\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in converting date into years: {e}\")\n",
    "            raise e\n",
    "    \n",
    "        \n",
    "    def string_into_numeric(self, df: DataFrame) -> Tuple[\n",
    "        Annotated[DataFrame, \"df\"],\n",
    "        Annotated[list, \"categorical_features\"],\n",
    "        Annotated[list, \"numeric_features\"],\n",
    "        Annotated[list, \"labels\"]\n",
    "        ]:\n",
    "        \"\"\"\n",
    "        Changes features with string data type into numeric\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame befor transformation\n",
    "        Returns:\n",
    "                Tuple[\n",
    "            Annotated[DataFrame, \"df\"],\n",
    "            Annotated[list, \"categorical_features\"],\n",
    "            Annotated[list, \"numeric_features\"],\n",
    "            Annotated[list, \"labels\"]\n",
    "            ]: \n",
    "            - df: DataFrame befor transformation\n",
    "            - categorical_features: List of categorical features\n",
    "            - numeric_features: List of numeric features\n",
    "            - labels: List of labels\n",
    "        \"\"\"\n",
    "        try:\n",
    "            categorical_features = [\"away_team\", \"city\", \"country\", \"home_team\", \"year\", \"tournament\"]\n",
    "            numeric_features = [\"neutral\"]\n",
    "            labels = [\"home_score\", \"away_score\"]\n",
    "            original_columns = df.columns\n",
    "            columns_to_transformation = [org_col for org_col in original_columns if org_col not in labels and org_col != \"year\"]\n",
    "\n",
    "            combined_home_away_team = df.select(col(\"home_team\") \\\n",
    "                                      .alias(\"team\")) \\\n",
    "                                      .union(df.select(col(\"away_team\") \\\n",
    "                                      .alias(\"team\"))) \\\n",
    "                                      .distinct()\n",
    "            \n",
    "            team_indexer = StringIndexer(inputCol=\"team\", outputCol=\"team_index\")\n",
    "            indexed_team = team_indexer.fit(combined_home_away_team).transform(combined_home_away_team)\n",
    "\n",
    "            df_with_home_index = df \\\n",
    "                .join(indexed_team.withColumnRenamed(\"team_index\", \"home_team_index\"), \n",
    "                      df.home_team == indexed_team.team, \"left\") \\\n",
    "                .drop(\"team\")\n",
    "            \n",
    "            df = df_with_home_index \\\n",
    "                .join(indexed_team.withColumnRenamed(\"team_index\", \"away_team_index\"), \n",
    "                      df_with_home_index.away_team == indexed_team.team, \"left\") \\\n",
    "                .drop(\"team\")\n",
    "                    \n",
    "            string_categorcial = [\"city\", \"country\", \"tournament\"]\n",
    "            for cat in string_categorcial:\n",
    "                string_indexer = StringIndexer(inputCol=cat, outputCol=cat + \"_index\")\n",
    "                df = string_indexer.fit(df).transform(df)\n",
    "\n",
    "            df = df.withColumn(\"neutral_index\", when(col(\"neutral\") == True, 1).otherwise(0))\n",
    "\n",
    "            for tr_col in columns_to_transformation:\n",
    "                df = df.drop(tr_col)\n",
    "            \n",
    "            for new_col in df.columns:\n",
    "                for col_to_trans in columns_to_transformation:\n",
    "                    if new_col == col_to_trans + \"_index\":\n",
    "                        df = df.withColumnRenamed(new_col, col_to_trans)\n",
    "            \n",
    "            df = df.select(*original_columns)\n",
    "            return df, categorical_features, numeric_features, labels\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while changing string features into numeric: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def divide_data(self, df: DataFrame) -> Tuple[\n",
    "        Annotated[DataFrame, \"train_df\"], \n",
    "        Annotated[DataFrame, \"val_df\"],\n",
    "        Annotated[DataFrame, \"test_df\"]\n",
    "        ]:\n",
    "        \"\"\"\n",
    "        Divides data into training, validation and test datasets\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame befor spliting\n",
    "        Returns:\n",
    "            Tuple[Annotated[DataFrame, \"train_df\"], \n",
    "                  Annotated[DataFrame, \"val_df\"],\n",
    "                  Annotated[DataFrame, \"test_df\"]]:\n",
    "                - Training dataset \n",
    "                - Validation datset\n",
    "                - Testing datset\n",
    "        \"\"\"\n",
    "        try:\n",
    "            val_df, test_df = df.randomSplit([0.8, 0.2])\n",
    "            train_df, val_df = val_df.randomSplit([0.75, 0.25])\n",
    "            return train_df, val_df, test_df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while dividing data into training, validation, and test datasets: {e}\")\n",
    "            raise e\n",
    "   \n",
    "\n",
    "    def embedding_categorical_data(self, \n",
    "                                   df: DataFrame, \n",
    "                                   categorical_features: List[str], \n",
    "                                   numeric_features: List[str]\n",
    "                                   ) -> Tuple[tf.Tensor, List[tf.Tensor]]:\n",
    "        \"\"\"\n",
    "        Applies embedding on categorical data and prepares inputs for neural network\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame containing a dataset\n",
    "            categorical_features: List of categorical features\n",
    "            numeric_features: List of numeric features\n",
    "        Returns:\n",
    "            Tuple[tf.Tensor, List[tf.Tensor]]:\n",
    "                - A tensor representing concatenated continuous features Inputs \n",
    "                  and embeddings for the categoircal features \n",
    "                - A List containing inputs layers for each feature\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            tf.debugging.enable_check_numerics()\n",
    "            models = []\n",
    "            inputs = []\n",
    "\n",
    "            combined_home_away_team = df.select(col(\"home_team\").alias(\"team\")) \\\n",
    "                                         .union(df.select(col(\"away_team\").alias(\"team\"))) \\\n",
    "                                         .distinct()\n",
    "            home_team_unique = combined_home_away_team.select(\"team\").count()\n",
    "\n",
    "            for cat in categorical_features:\n",
    "                if cat == \"home_team\" or cat == \"away_team\":\n",
    "                    vocab_size = home_team_unique\n",
    "                else:\n",
    "                    vocab_size = df.select(cat).distinct().count()\n",
    "\n",
    "\n",
    "                output_dim = min(50, (vocab_size // 2) + 1)\n",
    "\n",
    "                inpt = Input(shape=(1,), name=\"input_\" + cat)\n",
    "                embed = Embedding(vocab_size + 1,\n",
    "                                  output_dim,\n",
    "                                  trainable=True,\n",
    "                                  embeddings_initializer=tf.initializers.random_normal) \\\n",
    "                                  (inpt)\n",
    "\n",
    "                embed_reshaped = Reshape(target_shape=(output_dim,))(embed)\n",
    "                models.append(embed_reshaped)\n",
    "                inputs.append(inpt)\n",
    "\n",
    "            num_input = Input(shape=(len(numeric_features),), name=\"input_number_features\")\n",
    "            models.append(num_input)\n",
    "            inputs.append(num_input)\n",
    "\n",
    "            merge_models = Concatenate()(models)\n",
    "            return merge_models, inputs\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while embedding categorical features: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def prepare_for_model(self, \n",
    "                          df: DataFrame, \n",
    "                          categorical_features: List[str], \n",
    "                          number_features: List[str], \n",
    "                          labels: List[str]\n",
    "                          ) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Prepares data for model entry\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame to prepare\n",
    "            categorical_features: List of categorcial features\n",
    "            number_features: List of categorcial features\n",
    "            labels: List of labels\n",
    "        Returns:\n",
    "            Dict[str, Dict[str, np.ndarray]]: \n",
    "                - A dictionary with two keys:\n",
    "                    - \"input_features\": A dictionary with every feature name as a key\n",
    "                       and each value is a numpy array containing the feature data\n",
    "                    - \"labels\": A numpy array containing labels data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = df.toPandas()\n",
    "            input_dict = {\n",
    "                \"input_features\": {},\n",
    "                \"labels\": {},\n",
    "                }\n",
    "            for cat in categorical_features:\n",
    "                input_dict[\"input_features\"][\"input_\" + cat] = df[cat].values\n",
    "            input_dict[\"input_features\"][\"input_number_features\"] = df[number_features].values\n",
    "            \n",
    "            for lab in labels:\n",
    "                input_dict[\"labels\"][lab] = df[lab].values\n",
    "\n",
    "            return input_dict           \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while preparing data for model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform_strategy(df: DataFrame) -> Tuple[\n",
    "        Annotated[dict, \"training_dataset\"], \n",
    "        Annotated[dict, \"test_dataset\"],\n",
    "        Annotated[dict, \"validation_dataset\"],\n",
    "        Annotated[list, \"merge_models\"],\n",
    "        Annotated[list, \"inputs\"]\n",
    "        ]:\n",
    "    \"\"\"\n",
    "    Handles TransformData operations \n",
    "    \n",
    "    Args:\n",
    "        df: Dataset for transforming\n",
    "    Returns:\n",
    "        Tuple[\n",
    "        Annotated[dict, \"training_dataset\"], \n",
    "        Annotated[dict, \"test_dataset\"],\n",
    "        Annotated[dict, \"validation_dataset\"],\n",
    "        Annotated[list, \"merge_models\"],\n",
    "        Annotated[list, \"inputs\"]\n",
    "        ]:\n",
    "            - training_dataset: Dictionary with training dataset\n",
    "            - test_dataset: Dictionary with test dataset\n",
    "            - validation_dataset: Dictionary with validation dataset\n",
    "            - merge_models: A tensor representing concatenated continuous features Inputs \n",
    "                            and embeddings for the categoircal features \n",
    "            - inputs: A List containing inputs layers for each feature\n",
    "    \"\"\"\n",
    "    try:\n",
    "        transform_data = TransformData()\n",
    "        deleted_empty_fields = transform_data.check_empty_fields(df)\n",
    "        date_into_years = transform_data.convert_date_into_years(deleted_empty_fields)\n",
    "        string_into_numeric, categorical_features, numeric_features, labels = transform_data.string_into_numeric(df=date_into_years)\n",
    "        training_df, validation_df, test_df = transform_data.divide_data(df=string_into_numeric)\n",
    "        \n",
    "        merge_models, inputs = transform_data.embedding_categorical_data(df=string_into_numeric, \n",
    "                                                                         categorical_features=categorical_features, \n",
    "                                                                         numeric_features=numeric_features)\n",
    "\n",
    "        training_dataset = transform_data.prepare_for_model(df=training_df, \n",
    "                                                            categorical_features=categorical_features, \n",
    "                                                            number_features=numeric_features, \n",
    "                                                            labels=labels)\n",
    "        \n",
    "        test_dataset = transform_data.prepare_for_model(df=validation_df, \n",
    "                                                        categorical_features=categorical_features, \n",
    "                                                        number_features=numeric_features, \n",
    "                                                        labels=labels)\n",
    "        \n",
    "        validation_dataset = transform_data.prepare_for_model(df=test_df, \n",
    "                                                              categorical_features=categorical_features, \n",
    "                                                              number_features=numeric_features, \n",
    "                                                              labels=labels)\n",
    "        \n",
    "        return training_dataset, test_dataset, validation_dataset, merge_models, inputs\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in preparing data for model: {e}\")\n",
    "        raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

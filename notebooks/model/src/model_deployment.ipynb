{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import Dict, List, Tuple\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Class for deploying neural network\n",
    "    \"\"\"\n",
    "        \n",
    "    def model_deploy(self, merge_models: tf.Tensor, inputs: List[tf.Tensor]) -> Model:\n",
    "        \"\"\"\n",
    "        Creates a multi-input and multi-output neural network model \n",
    "\n",
    "        Args:\n",
    "            merge_models: A tensor that combined continuous features and embeddings from categorical features\n",
    "            inputs: A list containing the Input layer for each feature\n",
    "\n",
    "        Returns:\n",
    "            Model: A prepared structure of model \n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            x = Dense(300, activation='relu', kernel_regularizer=l2(0.01))(merge_models)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dense(300, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            home_score_output = Dense(1, activation=None, name=\"home_score\")(x)\n",
    "            away_score_output = Dense(1, activation=None, name=\"away_score\")(x)\n",
    "\n",
    "            model = Model(inputs=inputs, outputs=[home_score_output, away_score_output])\n",
    "            optimizer = SGD(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, \n",
    "                          loss={\"home_score\": \"mae\", \"away_score\": \"mae\"},\n",
    "                          metrics={\"home_score\": RootMeanSquaredError(),\n",
    "                                   \"away_score\": RootMeanSquaredError()                                  \n",
    "                                   })\n",
    "            model.summary()\n",
    "            logging.info(\"Successfully created multi-input and multi-output neural network model\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in the model deploying\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def model_train(self, \n",
    "                    model: Model, \n",
    "                    training_dataset: Dict[str, Dict[str, np.ndarray]], \n",
    "                    validation_dataset: Dict[str, Dict[str, np.ndarray]], \n",
    "                    epochs: int = 10\n",
    "                    ) -> Tuple[Model, History]:\n",
    "        \"\"\"\n",
    "        Trains the model on the training dataset and validate on new dataset\n",
    "\n",
    "        Args:\n",
    "            model: Allready prepared model\n",
    "            training_dataset: Training dataset\n",
    "            validation_dataset: Validation dataset\n",
    "            epochs: Number of epochs for model to train\n",
    "        Returns:\n",
    "            Model: Trained model\n",
    "            History: History of metrics all epochs during training\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"\\nModel training:\")\n",
    "            \n",
    "            training_features = training_dataset[\"input_features\"]\n",
    "            training_targets = training_dataset[\"targets\"]\n",
    "            validation_features = validation_dataset[\"input_features\"]\n",
    "            validation_targets = validation_dataset[\"targets\"]\n",
    "            \n",
    "            history = model.fit(training_features, \n",
    "                      training_targets, \n",
    "                      epochs=epochs,\n",
    "                      validation_data=(validation_features, \n",
    "                                       validation_targets)\n",
    "                                )\n",
    "            logging.info(\"Successfully trained the model\")\n",
    "            return model, history\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in model training: {e}\")\n",
    "            raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

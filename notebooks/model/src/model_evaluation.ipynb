{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import logging\n",
    "from typing import Tuple, Union, Dict, Annotated\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluate:\n",
    "    \"\"\"\n",
    "    Class for model evaluation and calculating predictions\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model: Model, \n",
    "                 test_dataset: Dict[str, Dict[str, np.ndarray]]\n",
    "                 ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: Trained tensorflow.keras model\n",
    "            test_dataset: Dictionary test dataset\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.test_targets = test_dataset[\"targets\"]\n",
    "        self.test_features = test_dataset[\"input_features\"]\n",
    "\n",
    "\n",
    "    def model_predict(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Makes predictions on a test dataset\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]:\n",
    "                - 'home_score' predictions\n",
    "                - 'away_score' predictions\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"\\nData prediction:\")\n",
    "            predictions = self.model.predict(self.test_features)\n",
    "            home_score_predictions, away_score_predictions = predictions\n",
    "            logging.info(\"Successfully predicted data on the model\")\n",
    "            return home_score_predictions, away_score_predictions\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in model prediction: {e}\")\n",
    "            raise e\n",
    "        \n",
    "    def calculate_metrics(self) -> Tuple[\n",
    "        Annotated[float, \"loss\"],\n",
    "        Annotated[float, \"home_loss\"],\n",
    "        Annotated[float, \"away_loss\"],\n",
    "        Annotated[float, \"home_rmse\"],\n",
    "        Annotated[float, \"away_rmse\"]\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Calculates model loss\n",
    "\n",
    "        Returns:\n",
    "            Tuple[\n",
    "        Annotated[float, \"loss\"],\n",
    "        Annotated[float, \"home_loss\"],\n",
    "        Annotated[float, \"away_loss\"],\n",
    "        Annotated[float, \"home_rmse\"],\n",
    "        Annotated[float, \"away_rmse\"]\n",
    "            ]:\n",
    "            - loss: loss value\n",
    "            - home_loss: 'home_score' loss value\n",
    "            - away_loss: 'away_score' loss value\n",
    "            - home_rmse: 'home_score' Root Mean Squared Error value\n",
    "            - away_rmse: 'away_score' Root Mean Squared Error value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"\\nCalculating metrics:\")\n",
    "            loss, home_loss, away_loss, home_rmse, away_rmse = self.model.evaluate(self.test_features, self.test_targets)\n",
    "            logging.info(\"Successfully model evaluated\")\n",
    "            return loss, home_loss, away_loss, home_rmse, away_rmse\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in model evaluation: {e}\")\n",
    "            raise e \n",
    "        \n",
    "    def round_results(self, predictions: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Changes continuous into discreet values\n",
    "        \n",
    "        Args:\n",
    "            predictions: Predictions with continuous values\n",
    "        Returns:\n",
    "            np.ndarray: Predictions with discreet values\n",
    "        \"\"\"\n",
    "        try:\n",
    "            predictions_rounded = np.round(predictions)\n",
    "            predictions_reshaped = predictions_rounded.reshape((len(predictions_rounded)))\n",
    "            return predictions_reshaped\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while converting continuous into discreet values: {e}\")\n",
    "            raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
